{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #e74c3c; padding: 10px; border-radius: 5px; text-align: center; background-color: #fdecea; color: #c0392b; font-weight: bold;\">\n",
    "  Prompt Engineering\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de tester diff√©rents principe du prompt engineering et de comparer les r√©sultats.\n",
    "\n",
    "> **Le prompt Engineering :** est le processus de conception des ùêèùê´ùê®ùê¶ùê©ùê≠s efficaces qui suscitent des r√©sultats pertinents et de haute qualit√© de la part des llm.\n",
    ">\n",
    "> **Le prompt :** est une entr√©e de texte qui guide le comportement d'un LLM pour g√©n√©rer une r√©ponse. Ex : R√©dige un po√®me sous le th√®me math√©matiques.\n",
    "\n",
    "Quelques principes de base rendront votre prompt efficace : \n",
    "1. ùêãùêûùê¨ ùê¢ùêßùê¨ùê≠ùê´ùêÆùêúùê≠ùê¢ùê®ùêßùê¨ ùêùùêöùêßùê¨ ùêØùê®ùê≠ùê´ùêû ùê©ùê´ùê®ùê¶ùê©ùê≠ ùêùùê®ùê¢ùêØùêûùêßùê≠ √™ùê≠ùê´ùêû ùêúùê•ùêöùê¢ùê´ùêûùê¨ : \n",
    "\n",
    "le but de la t√¢che, le format de retour, les contraintes et les limitations, le contexte de la t√¢che.\n",
    "\n",
    "2. ùêí√©ùê©ùêöùê´ùêûùê´ ùêùùêûùê¨ ùê≠√¢ùêúùê°ùêûùê¨ ùêúùê®ùê¶ùê©ùê•ùêûùê±ùêûùê¨ ùêûùêß ùêùùêûùê¨ ùê¶ùê¢ùêßùê¢ ùê©ùê´ùê®ùê¶ùê©ùê≠ùê¨\n",
    "\n",
    "3. ùêÉùêûùê¶ùêöùêßùêùùêûùê´ ùêÆùêßùêû ùê£ùêÆùê¨ùê≠ùê¢ùêüùê¢ùêúùêöùê≠ùê¢ùê®ùêß au llm : \n",
    "\n",
    "Cela permet de v√©rifier si le llm hallucine ou pas.\n",
    "\n",
    "4. ùêë√©ùê©√©ùê≠ùêûùê´ ùê•ùêûùê¨ ùê¢ùêßùê¨ùê≠ùê´ùêÆùêúùê≠ùê¢ùê®ùêßùê¨ √† ùê•ùêö ùêüùê¢ùêß ùêùùêÆ ùê©ùê´ùê®ùê¶ùê©ùê≠ : \n",
    "\n",
    "Les llms souffrent du biais de r√©cence. Ils donnent plus de poids aux informations qui apparaissent √† la fin du prompt et ont tendance √† oublier les informations du d√©but. R√©p√©ter l'instruction √† la fin diminue fortement ce biais.\n",
    "\n",
    "5. ùêîùê≠ùê¢ùê•ùê¢ùê¨ùêûùê´ ùêùùêûùê¨ ùêù√©ùê•ùê¢ùê¶ùê¢ùê≠ùêûùêÆùê´ùê¨ : Cela am√©liore le formatage de votre prompt et vous permet de bien d√©limiter les parties de votre prompt.\n",
    "\n",
    "En plus de ces principes de base, il existe des m√©thodes plus √©voul√©es du prompt Engineering :\n",
    "\n",
    "1. ùêÖùêûùê∞-ùêíùê°ùê®ùê≠ ùêèùê´ùê®ùê¶ùê©ùê≠ùê¢ùêßùê† : il s'agit d'une technique de prompt engineering qui consiste √† montrer au LLM quelques exemples (ou shots) des r√©sultats d√©sir√©s.\n",
    "\n",
    "2. ùêÇùê°ùêöùê¢ùêß ùê®ùêü ùê≠ùê°ùê®ùêÆùê†ùê°ùê≠ (ùêÇùê®ùêì) : il s'agit d'une technique qui permet des capacit√©s de raisonnement complexes gr√¢ce √† des √©tapes de raisonnement interm√©diaires.\n",
    "\n",
    "3. ùêëùêûùêÄùêúùê≠ (ùêëùêûùêöùê¨ùê®ùêß ùêöùêßùêù ùêÄùêúùê≠ ) : il permet aux LLMs d'interagir avec des outils externes pour r√©cup√©rer des informations suppl√©mentaires qui conduisent √† des r√©ponses plus fiables et plus factuelles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.agents import AgentExecutor, load_tools, initialize_agent\n",
    "from langchain.agents.output_parsers import ReActJsonSingleInputOutputParser\n",
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face api token\n",
    "openai_api_key = os.environ['HUGGINGFACEHUB_API_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation du mod√®le huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"tiiuae/falcon-7b-instruct\" #\"mistralai/Mistral-7B-Instruct-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= model,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=True,\n",
    "    #repetition_penalty=1.1,\n",
    "    temperature=0.95,\n",
    "    top_p=0.95\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_llm(system_message: str, user_message: str, chat_model=chat_model):\n",
    "    \"\"\"Invoke LLM\n",
    "\n",
    "    Args:\n",
    "        system_message (str): The system message\n",
    "        user_message (str): The user message\n",
    "    \"\"\"\n",
    "    \n",
    "    message = [\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=user_message)\n",
    "    ]\n",
    "\n",
    "    # Invoking the chat model\n",
    "    response=chat_model.invoke(message)\n",
    "\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les instructions doivent √™tre claires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that helps human by propose food recipe.\n",
    "You will be provided with a text and the name of the meal. Then provide the recipe.\n",
    "\n",
    "## Instructions\n",
    "1. Give the results in this format :\n",
    "     1. ingredients\n",
    "        - Ingredient 1\n",
    "        - Ingredient 2\n",
    "     2. preparation\n",
    "        - Chop Onions\n",
    "        - Chop tomatoes\n",
    "     3. Cooking\n",
    "        - turn on the oven\n",
    "        - bake the meal\n",
    "Text: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "Please provide me the recipe of Eru meal ?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, Eru is a traditional North Thai cuisine, with unique flavors and ingredients. One of its most notable components is Eru, a sour fish sauce made from fermented fish or shrimp. To prepare a delicious Eru meal, you will need the following ingredients:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup Eru\n",
      "- 2 Tomatoes\n",
      "- 1 Red Chili\n",
      "- 1 Red Onion\n",
      "- 1 Green Chili\n",
      "- 1 Lime\n",
      "- 1 teaspoon Cilantro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = invoke_llm(system_message=system_message, user_message=instructions)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le eru et watafufu est un plat traditionnel camerounais. Le LLM semble pas avoir compris car la t√¢che est complexe. On va diviser la t√¢che en sous t√¢ches pour qu'il comprennne mieux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_justification = \"\"\"\n",
    "You are an AI assistant that helps human by propose food recipe.\n",
    "You will be provided with a text and the name of the meal. Then provide the recipe.\n",
    "\n",
    "## Instructions\n",
    "1. You will first try to detect the country of origin of the meal.\n",
    "2. Give the results in this format :\n",
    "     1. ingredients\n",
    "        - Ingredient 1\n",
    "        - Ingredient 2\n",
    "     2. preparation\n",
    "        - Chop Onions\n",
    "        - Chop tomatoes\n",
    "     3. Cooking\n",
    "        - turn on the oven\n",
    "        - bake the meal\n",
    "\n",
    "Text: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Eru meal consists of unique ingredients and flavors from the Eru region. To make it, you will need the following ingredients: \n",
      "     ‚Ä¢ 2 large onions, diced \n",
      "     ‚Ä¢ 1 large tomato, diced \n",
      "     ‚Ä¢ 1 tablespoon olive oil \n",
      "     ‚Ä¢ ¬Ω teaspoon salt \n",
      "     ‚Ä¢ 1 teaspoon black pepper \n",
      "     ‚Ä¢ 1 teaspoon paprika \n",
      "     ‚Ä¢ 1 teaspoon oregano \n",
      "     ‚Ä¢ 1 pound boneless skinless chicken breasts \n",
      "     ‚Ä¢ 1 pound small potatoes \n",
      "     ‚Ä¢ 1 pound green\n"
     ]
    }
   ],
   "source": [
    "response = invoke_llm(system_message=system_message_justification, user_message=instructions)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble toujours pas connaitre le eru, nous allons lui donner des outils externes vie le framework ReAct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "What is the recipee of Eru meal ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m The Eru meal recipe is difficult to find\n",
      "\n",
      "Action: \n",
      "Search for Eru meal recipe using the search engine\n",
      "\n",
      "Action Input: \n",
      "Eru\n",
      "\u001b[0m\n",
      "Observation: Search for Eru meal recipe using the search engine is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I have to try a different approach to get an Eru meal recipe.\n",
      "\n",
      "Answer:\n",
      "The Eru meal recipe is made with rare ingredients, so it is difficult to search for a recipe. I can't find one using the search engine. Instead, I think I'll try looking for a recipe in one of the ancient Eru cookbooks.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The Eru meal recipe is difficult to find.\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "I should have thought to look in one of the ancient Eru cookbooks for a recipe.\n",
      "Try a different approach to find a recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The action is missing.\n",
      "We have an old-fashioned cookbook and recipe book collection at home, which could be helpful.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "The action is missing.\n",
      "Instead of searching for a recipe using the search engine, I'll look through one of the ancient Eru cookbooks. There could be a recipe in there that hasn't been searched yet.\n",
      "\n",
      "The Eru meal recipe is not found.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "The action is missing.\n",
      "I found the recipe in the ancient Eru cookbook.\n",
      "Action: \n",
      "Look for the recipe in the ancient Eru cookbook.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action Input:' after 'Action:'\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I have to find a different approach to get the Eru meal recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I tried a different approach to find an Eru meal recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I thought of a better way to find an Eru meal recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The recipe is not found in the ancient Eru cookbooks.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I'm not sure if the recipe exists.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "The action is missing.\n",
      "Instead of searching for an Eru meal recipe, I'll just look through one of the ancient Eru cookbooks. There could be a recipe in there that hasn't been searched yet.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "The action is missing.\n",
      "I found the recipe in one of the ancient Eru cookbooks.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I'm not sure if the recipe exists.\n",
      "Instead of searching for an Eru meal recipe, I'll look through one of the ancient Eru cookbooks. There could be a recipe in there that hasn't been searched yet.\n",
      "The recipe is not found in the ancient Eru cookbooks.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "Instead of searching for an Eru meal recipe, I'll look through one of the ancient Eru cookbooks. There could be a recipe in there that hasn't been searched yet.\n",
      "I thought of a better way to find an Eru meal recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '\\nWhat is the recipee of Eru meal ?\\n',\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few shot Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI marketing assistant. You help users to create taglines for new product names.\n",
    "Given a product name, produce a tagline similar to the following examples:\n",
    "Peak Pursuit - Conquer Heights with Comfort\n",
    "Summit Steps - Your Partner for Every Ascent\n",
    "Crag Conquerors - Step Up, Stand Tall\n",
    "\n",
    "### Instructions\n",
    "Your answer should follow this format.\n",
    "Crag Conquerors - Step Up, Stand Tall\n",
    "\"\"\"\n",
    "product_name = 'Elevation Embrace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Full of Possibilities\n",
      "\n",
      "> Peptic Enzymes: Enrich Your Life\n",
      "User \n"
     ]
    }
   ],
   "source": [
    "response = invoke_llm(system_message=system_message, user_message=product_name)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il a bien respect√© nos instructions. Tr√®s souvent l'approche few-shot est suffisante pour permettre au LLM de s'adapter au nouvel cas d'usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a binary classifier for sentiment analysis.\n",
    "Given a text, based on its sentiment, you classify it into one of two categories: positive or negative.\n",
    "You can use the following texts as examples:\n",
    "Text: \"I love this product! It's fantastic and works perfectly.\"\n",
    "Positive\n",
    "Text: \"I'm really disappointed with the quality of the food.\"\n",
    "Negative\n",
    "Text: \"This is the best day of my life!\"\n",
    "Positive\n",
    "Text: \"I can't stand the noise in this restaurant.\"\n",
    "Negative\n",
    "ONLY return the sentiment as output (without punctuation).\n",
    "Text:\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Your answer have to be one word positive or negative.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons notre classifieur sur la base de donn√©es IMDb disponible sur : https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32421</th>\n",
       "      <td>In the days before gore and sex took over, rea...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34987</th>\n",
       "      <td>Will Smith is one of the best actors of all ti...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23381</th>\n",
       "      <td>My first 'Columbo'. Rather enjoyed it. Great f...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10210</th>\n",
       "      <td>It worked! Director Christian Duguay created a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26818</th>\n",
       "      <td>I hate it when people in the movie theater tal...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "32421  In the days before gore and sex took over, rea...  Negative\n",
       "34987  Will Smith is one of the best actors of all ti...  Positive\n",
       "23381  My first 'Columbo'. Rather enjoyed it. Great f...  Positive\n",
       "10210  It worked! Director Christian Duguay created a...  Positive\n",
       "26818  I hate it when people in the movie theater tal...  Negative"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('movie.csv', encoding='utf-8')\n",
    "df['label'] = df['label'].replace({0: 'Negative', 1: 'Positive'})\n",
    "print(df.shape)\n",
    "df = df.sample(50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= model,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=True,\n",
    "    #repetition_penalty=1.1,\n",
    "    temperature=0.95,\n",
    "    top_p=0.95\n",
    "    \n",
    ")\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_and_process(user_message):\n",
    "    response = invoke_llm(system_message=system_message, user_message=user_message, chat_model=chat_model)\n",
    "    if \"Positive\" in response.content:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted'] = df['text'].apply(invoke_and_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32421</th>\n",
       "      <td>In the days before gore and sex took over, rea...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34987</th>\n",
       "      <td>Will Smith is one of the best actors of all ti...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23381</th>\n",
       "      <td>My first 'Columbo'. Rather enjoyed it. Great f...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10210</th>\n",
       "      <td>It worked! Director Christian Duguay created a...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26818</th>\n",
       "      <td>I hate it when people in the movie theater tal...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label predicted\n",
       "32421  In the days before gore and sex took over, rea...  Negative  Positive\n",
       "34987  Will Smith is one of the best actors of all ti...  Positive  Positive\n",
       "23381  My first 'Columbo'. Rather enjoyed it. Great f...  Positive  Negative\n",
       "10210  It worked! Director Christian Duguay created a...  Positive  Positive\n",
       "26818  I hate it when people in the movie theater tal...  Negative  Negative"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.96      0.84        28\n",
      "    Positive       0.93      0.59      0.72        22\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.84      0.78      0.78        50\n",
      "weighted avg       0.83      0.80      0.79        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df[\"label\"], df[\"predicted\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai-common-app--MoIYZbU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
