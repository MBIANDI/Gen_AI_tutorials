{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #e74c3c; padding: 10px; border-radius: 5px; text-align: center; background-color: #fdecea; color: #c0392b; font-weight: bold;\">\n",
    "  Prompt Engineering\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce notebook est de tester différents principe du prompt engineering et de comparer les résultats.\n",
    "\n",
    "> **Le prompt Engineering :** est le processus de conception des 𝐏𝐫𝐨𝐦𝐩𝐭s efficaces qui suscitent des résultats pertinents et de haute qualité de la part des llm.\n",
    ">\n",
    "> **Le prompt :** est une entrée de texte qui guide le comportement d'un LLM pour générer une réponse. Ex : Rédige un poème sous le thème mathématiques.\n",
    "\n",
    "Quelques principes de base rendront votre prompt efficace : \n",
    "1. 𝐋𝐞𝐬 𝐢𝐧𝐬𝐭𝐫𝐮𝐜𝐭𝐢𝐨𝐧𝐬 𝐝𝐚𝐧𝐬 𝐯𝐨𝐭𝐫𝐞 𝐩𝐫𝐨𝐦𝐩𝐭 𝐝𝐨𝐢𝐯𝐞𝐧𝐭 ê𝐭𝐫𝐞 𝐜𝐥𝐚𝐢𝐫𝐞𝐬 : \n",
    "\n",
    "le but de la tâche, le format de retour, les contraintes et les limitations, le contexte de la tâche.\n",
    "\n",
    "2. 𝐒é𝐩𝐚𝐫𝐞𝐫 𝐝𝐞𝐬 𝐭â𝐜𝐡𝐞𝐬 𝐜𝐨𝐦𝐩𝐥𝐞𝐱𝐞𝐬 𝐞𝐧 𝐝𝐞𝐬 𝐦𝐢𝐧𝐢 𝐩𝐫𝐨𝐦𝐩𝐭𝐬\n",
    "\n",
    "3. 𝐃𝐞𝐦𝐚𝐧𝐝𝐞𝐫 𝐮𝐧𝐞 𝐣𝐮𝐬𝐭𝐢𝐟𝐢𝐜𝐚𝐭𝐢𝐨𝐧 au llm : \n",
    "\n",
    "Cela permet de vérifier si le llm hallucine ou pas.\n",
    "\n",
    "4. 𝐑é𝐩é𝐭𝐞𝐫 𝐥𝐞𝐬 𝐢𝐧𝐬𝐭𝐫𝐮𝐜𝐭𝐢𝐨𝐧𝐬 à 𝐥𝐚 𝐟𝐢𝐧 𝐝𝐮 𝐩𝐫𝐨𝐦𝐩𝐭 : \n",
    "\n",
    "Les llms souffrent du biais de récence. Ils donnent plus de poids aux informations qui apparaissent à la fin du prompt et ont tendance à oublier les informations du début. Répéter l'instruction à la fin diminue fortement ce biais.\n",
    "\n",
    "5. 𝐔𝐭𝐢𝐥𝐢𝐬𝐞𝐫 𝐝𝐞𝐬 𝐝é𝐥𝐢𝐦𝐢𝐭𝐞𝐮𝐫𝐬 : Cela améliore le formatage de votre prompt et vous permet de bien délimiter les parties de votre prompt.\n",
    "\n",
    "En plus de ces principes de base, il existe des méthodes plus évoulées du prompt Engineering :\n",
    "\n",
    "1. 𝐅𝐞𝐰-𝐒𝐡𝐨𝐭 𝐏𝐫𝐨𝐦𝐩𝐭𝐢𝐧𝐠 : il s'agit d'une technique de prompt engineering qui consiste à montrer au LLM quelques exemples (ou shots) des résultats désirés.\n",
    "\n",
    "2. 𝐂𝐡𝐚𝐢𝐧 𝐨𝐟 𝐭𝐡𝐨𝐮𝐠𝐡𝐭 (𝐂𝐨𝐓) : il s'agit d'une technique qui permet des capacités de raisonnement complexes grâce à des étapes de raisonnement intermédiaires.\n",
    "\n",
    "3. 𝐑𝐞𝐀𝐜𝐭 (𝐑𝐞𝐚𝐬𝐨𝐧 𝐚𝐧𝐝 𝐀𝐜𝐭 ) : il permet aux LLMs d'interagir avec des outils externes pour récupérer des informations supplémentaires qui conduisent à des réponses plus fiables et plus factuelles.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.agents import AgentExecutor, load_tools, initialize_agent\n",
    "from langchain.agents.output_parsers import ReActJsonSingleInputOutputParser\n",
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging face api token\n",
    "openai_api_key = os.environ['HUGGINGFACEHUB_API_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation du modèle huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"tiiuae/falcon-7b-instruct\" #\"mistralai/Mistral-7B-Instruct-v0.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= model,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=True,\n",
    "    #repetition_penalty=1.1,\n",
    "    temperature=0.95,\n",
    "    top_p=0.95\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_llm(system_message: str, user_message: str, chat_model=chat_model):\n",
    "    \"\"\"Invoke LLM\n",
    "\n",
    "    Args:\n",
    "        system_message (str): The system message\n",
    "        user_message (str): The user message\n",
    "    \"\"\"\n",
    "    \n",
    "    message = [\n",
    "        SystemMessage(content=system_message),\n",
    "        HumanMessage(content=user_message)\n",
    "    ]\n",
    "\n",
    "    # Invoking the chat model\n",
    "    response=chat_model.invoke(message)\n",
    "\n",
    "    return response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les instructions doivent être claires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI assistant that helps human by propose food recipe.\n",
    "You will be provided with a text and the name of the meal. Then provide the recipe.\n",
    "\n",
    "## Instructions\n",
    "1. Give the results in this format :\n",
    "     1. ingredients\n",
    "        - Ingredient 1\n",
    "        - Ingredient 2\n",
    "     2. preparation\n",
    "        - Chop Onions\n",
    "        - Chop tomatoes\n",
    "     3. Cooking\n",
    "        - turn on the oven\n",
    "        - bake the meal\n",
    "Text: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "Please provide me the recipe of Eru meal ?\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Sure, Eru is a traditional North Thai cuisine, with unique flavors and ingredients. One of its most notable components is Eru, a sour fish sauce made from fermented fish or shrimp. To prepare a delicious Eru meal, you will need the following ingredients:\n",
      "\n",
      "Ingredients:\n",
      "- 1 cup Eru\n",
      "- 2 Tomatoes\n",
      "- 1 Red Chili\n",
      "- 1 Red Onion\n",
      "- 1 Green Chili\n",
      "- 1 Lime\n",
      "- 1 teaspoon Cilantro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = invoke_llm(system_message=system_message, user_message=instructions)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le eru et watafufu est un plat traditionnel camerounais. Le LLM semble pas avoir compris car la tâche est complexe. On va diviser la tâche en sous tâches pour qu'il comprennne mieux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_justification = \"\"\"\n",
    "You are an AI assistant that helps human by propose food recipe.\n",
    "You will be provided with a text and the name of the meal. Then provide the recipe.\n",
    "\n",
    "## Instructions\n",
    "1. You will first try to detect the country of origin of the meal.\n",
    "2. Give the results in this format :\n",
    "     1. ingredients\n",
    "        - Ingredient 1\n",
    "        - Ingredient 2\n",
    "     2. preparation\n",
    "        - Chop Onions\n",
    "        - Chop tomatoes\n",
    "     3. Cooking\n",
    "        - turn on the oven\n",
    "        - bake the meal\n",
    "\n",
    "Text: \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Eru meal consists of unique ingredients and flavors from the Eru region. To make it, you will need the following ingredients: \n",
      "     • 2 large onions, diced \n",
      "     • 1 large tomato, diced \n",
      "     • 1 tablespoon olive oil \n",
      "     • ½ teaspoon salt \n",
      "     • 1 teaspoon black pepper \n",
      "     • 1 teaspoon paprika \n",
      "     • 1 teaspoon oregano \n",
      "     • 1 pound boneless skinless chicken breasts \n",
      "     • 1 pound small potatoes \n",
      "     • 1 pound green\n"
     ]
    }
   ],
   "source": [
    "response = invoke_llm(system_message=system_message_justification, user_message=instructions)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semble toujours pas connaitre le eru, nous allons lui donner des outils externes vie le framework ReAct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReAct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"serpapi\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType, initialize_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose = True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Search(query: str, **kwargs: Any) -> str - A search engine. Useful for when you need to answer questions about current events. Input should be a search query.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Search]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "What is the recipee of Eru meal ?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m The Eru meal recipe is difficult to find\n",
      "\n",
      "Action: \n",
      "Search for Eru meal recipe using the search engine\n",
      "\n",
      "Action Input: \n",
      "Eru\n",
      "\u001b[0m\n",
      "Observation: Search for Eru meal recipe using the search engine is not a valid tool, try one of [Search].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I have to try a different approach to get an Eru meal recipe.\n",
      "\n",
      "Answer:\n",
      "The Eru meal recipe is made with rare ingredients, so it is difficult to search for a recipe. I can't find one using the search engine. Instead, I think I'll try looking for a recipe in one of the ancient Eru cookbooks.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The Eru meal recipe is difficult to find.\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "I should have thought to look in one of the ancient Eru cookbooks for a recipe.\n",
      "Try a different approach to find a recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The action is missing.\n",
      "We have an old-fashioned cookbook and recipe book collection at home, which could be helpful.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "The action is missing.\n",
      "Instead of searching for a recipe using the search engine, I'll look through one of the ancient Eru cookbooks. There could be a recipe in there that hasn't been searched yet.\n",
      "\n",
      "The Eru meal recipe is not found.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "The action is missing.\n",
      "I found the recipe in the ancient Eru cookbook.\n",
      "Action: \n",
      "Look for the recipe in the ancient Eru cookbook.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action Input:' after 'Action:'\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I have to find a different approach to get the Eru meal recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I tried a different approach to find an Eru meal recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I thought of a better way to find an Eru meal recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The recipe is not found in the ancient Eru cookbooks.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I'm not sure if the recipe exists.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "The action is missing.\n",
      "Instead of searching for an Eru meal recipe, I'll just look through one of the ancient Eru cookbooks. There could be a recipe in there that hasn't been searched yet.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "The search engine is not a valid tool to find an Eru meal recipe.\n",
      "The action is missing.\n",
      "I found the recipe in one of the ancient Eru cookbooks.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "I'm not sure if the recipe exists.\n",
      "Instead of searching for an Eru meal recipe, I'll look through one of the ancient Eru cookbooks. There could be a recipe in there that hasn't been searched yet.\n",
      "The recipe is not found in the ancient Eru cookbooks.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\n",
      "Instead of searching for an Eru meal recipe, I'll look through one of the ancient Eru cookbooks. There could be a recipe in there that hasn't been searched yet.\n",
      "I thought of a better way to find an Eru meal recipe.\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': '\\nWhat is the recipee of Eru meal ?\\n',\n",
       " 'output': 'Agent stopped due to iteration limit or time limit.'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few shot Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are an AI marketing assistant. You help users to create taglines for new product names.\n",
    "Given a product name, produce a tagline similar to the following examples:\n",
    "Peak Pursuit - Conquer Heights with Comfort\n",
    "Summit Steps - Your Partner for Every Ascent\n",
    "Crag Conquerors - Step Up, Stand Tall\n",
    "\n",
    "### Instructions\n",
    "Your answer should follow this format.\n",
    "Crag Conquerors - Step Up, Stand Tall\n",
    "\"\"\"\n",
    "product_name = 'Elevation Embrace'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Full of Possibilities\n",
      "\n",
      "> Peptic Enzymes: Enrich Your Life\n",
      "User \n"
     ]
    }
   ],
   "source": [
    "response = invoke_llm(system_message=system_message, user_message=product_name)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il a bien respecté nos instructions. Très souvent l'approche few-shot est suffisante pour permettre au LLM de s'adapter au nouvel cas d'usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"\n",
    "You are a binary classifier for sentiment analysis.\n",
    "Given a text, based on its sentiment, you classify it into one of two categories: positive or negative.\n",
    "You can use the following texts as examples:\n",
    "Text: \"I love this product! It's fantastic and works perfectly.\"\n",
    "Positive\n",
    "Text: \"I'm really disappointed with the quality of the food.\"\n",
    "Negative\n",
    "Text: \"This is the best day of my life!\"\n",
    "Positive\n",
    "Text: \"I can't stand the noise in this restaurant.\"\n",
    "Negative\n",
    "ONLY return the sentiment as output (without punctuation).\n",
    "Text:\n",
    "\n",
    "### Instructions\n",
    "\n",
    "Your answer have to be one word positive or negative.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons notre classifieur sur la base de données IMDb disponible sur : https://www.kaggle.com/datasets/yasserh/imdb-movie-ratings-sentiment-analysis/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32421</th>\n",
       "      <td>In the days before gore and sex took over, rea...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34987</th>\n",
       "      <td>Will Smith is one of the best actors of all ti...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23381</th>\n",
       "      <td>My first 'Columbo'. Rather enjoyed it. Great f...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10210</th>\n",
       "      <td>It worked! Director Christian Duguay created a...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26818</th>\n",
       "      <td>I hate it when people in the movie theater tal...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label\n",
       "32421  In the days before gore and sex took over, rea...  Negative\n",
       "34987  Will Smith is one of the best actors of all ti...  Positive\n",
       "23381  My first 'Columbo'. Rather enjoyed it. Great f...  Positive\n",
       "10210  It worked! Director Christian Duguay created a...  Positive\n",
       "26818  I hate it when people in the movie theater tal...  Negative"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('movie.csv', encoding='utf-8')\n",
    "df['label'] = df['label'].replace({0: 'Negative', 1: 'Positive'})\n",
    "print(df.shape)\n",
    "df = df.sample(50)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id= model,\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=1024,\n",
    "    do_sample=True,\n",
    "    #repetition_penalty=1.1,\n",
    "    temperature=0.95,\n",
    "    top_p=0.95\n",
    "    \n",
    ")\n",
    "chat_model = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_and_process(user_message):\n",
    "    response = invoke_llm(system_message=system_message, user_message=user_message, chat_model=chat_model)\n",
    "    if \"Positive\" in response.content:\n",
    "        return \"Positive\"\n",
    "    else:\n",
    "        return \"Negative\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted'] = df['text'].apply(invoke_and_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32421</th>\n",
       "      <td>In the days before gore and sex took over, rea...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34987</th>\n",
       "      <td>Will Smith is one of the best actors of all ti...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23381</th>\n",
       "      <td>My first 'Columbo'. Rather enjoyed it. Great f...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10210</th>\n",
       "      <td>It worked! Director Christian Duguay created a...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26818</th>\n",
       "      <td>I hate it when people in the movie theater tal...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text     label predicted\n",
       "32421  In the days before gore and sex took over, rea...  Negative  Positive\n",
       "34987  Will Smith is one of the best actors of all ti...  Positive  Positive\n",
       "23381  My first 'Columbo'. Rather enjoyed it. Great f...  Positive  Negative\n",
       "10210  It worked! Director Christian Duguay created a...  Positive  Positive\n",
       "26818  I hate it when people in the movie theater tal...  Negative  Negative"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.75      0.96      0.84        28\n",
      "    Positive       0.93      0.59      0.72        22\n",
      "\n",
      "    accuracy                           0.80        50\n",
      "   macro avg       0.84      0.78      0.78        50\n",
      "weighted avg       0.83      0.80      0.79        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(df[\"label\"], df[\"predicted\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen-ai-common-app--MoIYZbU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
